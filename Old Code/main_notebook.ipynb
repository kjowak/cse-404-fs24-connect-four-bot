{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('connect4_dataset.csv')\n",
    "data.head()\n",
    "\n",
    "# Select columns pos01 to pos42\n",
    "columns = [f'pos_{i:02d}' for i in range(1, 43)]\n",
    "data.columns = columns + ['winner']\n",
    "X_ = data[columns]\n",
    "y = data['winner']\n",
    "\n",
    "# Function to convert each row to a 6x7 2D array\n",
    "def row_to_2d_array(row):\n",
    "    return np.array(row).reshape(6, 7)\n",
    "\n",
    "# Apply the function to each row\n",
    "X = X_.apply(row_to_2d_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table:\n",
      " [[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0 -1  0  0  1  0  0]\n",
      " [ 0 -1  0  0 -1  0  0]\n",
      " [ 1  1  1 -1  1 -1  0]\n",
      " [ 1  1 -1 -1 -1  1  0]]\n",
      "Winner: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "game_num = 2\n",
    "\n",
    "# Assuming data_2d_arrays is already defined and contains the 2D arrays\n",
    "# Display the 2D array for the a row\n",
    "print('Table:\\n', X[game_num])\n",
    "print('Winner:', y[game_num])\n",
    "\n",
    "array_to_plot = X.iloc[game_num]\n",
    "\n",
    "# Define a custom colormap\n",
    "cmap = mcolors.ListedColormap(['yellow', 'white', 'red'])\n",
    "bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Plot the 2D array\n",
    "plt.imshow(array_to_plot, cmap=cmap, norm=norm)\n",
    "plt.colorbar(ticks=[-1, 0, 1])\n",
    "plt.title('2D Array Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Very naive model that only actually learns if a board is won or not and by who."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Flatten the 6x7 2D arrays back to 1D arrays for logistic regression\n",
    "X_flat = X.apply(lambda x: x.flatten())\n",
    "X_flat = np.stack(X_flat.values)\n",
    "\n",
    "# Drop rows with NaN values in y\n",
    "non_nan_indices = ~np.isnan(y)\n",
    "X_flat = X_flat[non_nan_indices]\n",
    "y = y[non_nan_indices]\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (MLP) Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty naive approach, but it should still work in theory. Other models like Random Forest, SVM, etc, should be tried to see if they perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (376640, 42)\n",
      "y shape: (376640, 7)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('Old Code/c4_game_database.csv', on_bad_lines='skip')\n",
    "\n",
    "# Prepare the features (X) and the target labels (y)\n",
    "X = data.drop(columns=['winner']).values\n",
    "y_winner = data['winner'].values\n",
    "\n",
    "# Convert the 'winner' column into a 7-element probability vector\n",
    "y = np.zeros((len(y_winner), 7))\n",
    "\n",
    "y[y_winner == 1] = 1    # If Player 1 won, set all columns to 1\n",
    "y[y_winner == -1] = 0   # If Player 2 won, set all columns to 0\n",
    "y[y_winner == 0] = 0.5  # If tie, set all columns to 0.5\n",
    "\n",
    "# Check the shapes of X and y\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.2392\n",
      "Epoch [20/50], Loss: 0.2359\n",
      "Epoch [30/50], Loss: 0.2291\n",
      "Epoch [40/50], Loss: 0.2181\n",
      "Epoch [50/50], Loss: 0.2058\n",
      "Loss on test set: 0.2051\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Convert data to torch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the MLP model\n",
    "class Connect4MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Connect4MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 7)   # Output layer (7 probabilities for each column)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Sigmoid to output probabilities\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model2 = Connect4MLP()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model2(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation on test set\n",
    "model2.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    test_loss = criterion(test_outputs, y_test).item()\n",
    "    print(f'Loss on test set: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.2405\n",
      "Epoch [20/50], Loss: 0.2322\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Convert data to torch tensors, reshaping X for MLP input\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).reshape(-1, 42)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).reshape(-1, 42)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the MLP model\n",
    "class Connect4MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Connect4MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 64)   # Input layer with 42 features\n",
    "        self.fc2 = nn.Linear(64, 128)  # Hidden layers\n",
    "        self.fc3 = nn.Linear(128, 256)\n",
    "        self.fc4 = nn.Linear(256, 512)\n",
    "        self.fc5 = nn.Linear(512, 256)\n",
    "        self.fc6 = nn.Linear(256, 128)\n",
    "        self.fc7 = nn.Linear(128, 64)\n",
    "        self.fc8 = nn.Linear(64, 32)\n",
    "        self.fc9 = nn.Linear(32, 7)    # Output layer (7 probabilities for each column)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = torch.relu(self.fc7(x))\n",
    "        x = torch.relu(self.fc8(x))\n",
    "        x = torch.sigmoid(self.fc9(x))  # Sigmoid to output probabilities\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Connect4MLP()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    test_loss = criterion(test_outputs, y_test).item()\n",
    "    print(f'Loss on test set: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.2330\n",
      "Epoch [20/50], Loss: 0.1974\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).reshape(-1, 1, 6, 7)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).reshape(-1, 1, 6, 7)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "class Connect4CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Connect4CNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(32 * 6 * 7, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 7)  # Output layer (7 probabilities for each column)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Sigmoid to output probabilities\n",
    "        return x\n",
    "\n",
    "model3 = Connect4CNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model3.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model3.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model3(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "model3.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model3(X_test)\n",
    "    test_loss = criterion(test_outputs, y_test).item()\n",
    "    print(f'Loss on test set: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "data = pd.read_csv('Old Code/c4_game_database.csv')\n",
    "data = data.dropna()\n",
    "\n",
    "columns = [f'pos_{i:02d}' for i in range(1, 43)]\n",
    "X = data[columns]\n",
    "y = data['winner']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell will give you the probabilities of winning given a placement in each column. There are 7 outputs, one for each column in the Connect Four game. The model outputs a probability for each column, indicating the likelihood of winning if a piece is placed in that column. The column with the highest probability is the best move to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[0.5338113  0.5198696  0.5356338  0.51042956 0.53341067 0.47715053\n",
      "  0.5103585 ]]\n"
     ]
    }
   ],
   "source": [
    "new_data = np.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, -1, 1, 0, 0],\n",
    "    [0, 1, -1, 1, -1, 0, 0],\n",
    "    [1, -1, 1, -1, 1, 0, 0],\n",
    "    [-1, 1, -1, 1, -1, 1, 0],\n",
    "    [1, -1, 1, -1, 1, -1, 1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Convert to tensor and reshape to match (1, 1, 6, 7) format for the model\n",
    "new_data_tensor = torch.tensor(new_data, dtype=torch.float32).reshape(1, 1, 6, 7)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model = Connect4CNN()\n",
    "model.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    prediction = model(new_data_tensor)\n",
    "    prediction_np = prediction.numpy().flatten()\n",
    "\n",
    "    # Find the best column (index of the highest probability)\n",
    "    best_column = np.argmax(prediction_np)\n",
    "    print(\"Probabilities for each column:\", prediction_np)\n",
    "    print(\"Best column to play:\", best_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming `X` contains the 42 board positions reshaped as (num_samples, 6, 7)\n",
    "# and `y` contains the 7 probability targets for each move\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to torch tensors, reshaping X for CNN input\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).reshape(-1, 1, 6, 7)  # Add channel dimension\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).reshape(-1, 1, 6, 7)    # Add channel dimension\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the more complex CNN model\n",
    "class Connect4CNNComplex(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Connect4CNNComplex, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # Output size: 32x6x7\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # Output size: 64x6x7\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # Output size: 128x6x7\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Fully connected layers with Dropout\n",
    "        self.fc1 = nn.Linear(128 * 6 * 7, 256)   # Flatten and dense layer\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(128, 7)  # Output layer (7 probabilities for each column)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions with batch norm and ReLU activations\n",
    "        x = torch.relu(self.bn1(self.conv1(x)))\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = torch.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        # Flatten and pass through fully connected layers with Dropout and ReLU\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = torch.relu(self.dropout1(self.fc1(x)))\n",
    "        x = torch.relu(self.dropout2(self.fc2(x)))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Sigmoid to output probabilities\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Connect4CNNComplex()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression on probabilities\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    test_loss = criterion(test_outputs, y_test).item()\n",
    "    print(f'Loss on test set: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, -1, 1, 0, 0],\n",
    "    [0, 1, -1, 1, -1, 0, 0],\n",
    "    [1, -1, 1, -1, 1, 0, 0],\n",
    "    [-1, 1, -1, 1, -1, 1, 0],\n",
    "    [1, -1, 1, -1, 1, -1, 1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Convert to tensor and reshape to match (1, 1, 6, 7) format for the model\n",
    "new_data_tensor = torch.tensor(new_data, dtype=torch.float32).reshape(1, 1, 6, 7)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model = Connect4CNN()\n",
    "model.eval()\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    prediction = model(new_data_tensor)\n",
    "    prediction_np = prediction.numpy().flatten()\n",
    "\n",
    "    # Find the best column (index of the highest probability)\n",
    "    best_column = np.argmax(prediction_np)\n",
    "    print(\"Probabilities for each column:\", prediction_np)\n",
    "    print(\"Best column to play:\", best_column)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
