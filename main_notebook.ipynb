{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the CSV file\n",
    "data = pd.read_csv('c4_game_database.csv')\n",
    "data.head()\n",
    "\n",
    "# Select columns pos01 to pos42\n",
    "columns = [f'pos_{i:02d}' for i in range(1, 43)]\n",
    "X_ = data[columns]\n",
    "y = data['winner']\n",
    "\n",
    "# Function to convert each row to a 6x7 2D array\n",
    "def row_to_2d_array(row):\n",
    "    return np.array(row).reshape(6, 7)\n",
    "\n",
    "# Apply the function to each row\n",
    "X = X_.apply(row_to_2d_array, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table:\n",
      " [[ 0.  0.  1.  1.  1.  1.  0.]\n",
      " [ 0.  0.  1. -1. -1. -1.  0.]\n",
      " [ 0.  0.  1.  1.  1. -1.  0.]\n",
      " [ 0.  0. -1. -1.  1.  1. -1.]\n",
      " [ 1. -1. -1.  1. -1. -1.  1.]\n",
      " [ 1. -1. -1. -1.  1.  1. -1.]]\n",
      "Winner: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAGUCAYAAADQ9ZAkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh0ElEQVR4nO3de3BU9d3H8c8CyYZLduUaiCw0QuUOaoKSKIKiqRERKyIWREakFgkUmloFfBRQNFpHqzNgSiiCqEC8cVGBmsrVQmoIRikwFgZqUgEzUN0NERYN5/mjZWsIIJuc3RPye79mzkx3c3Z/30Mxb87u2cRlWZYlAABQrzVwegAAABB5BB8AAAMQfAAADEDwAQAwAMEHAMAABB8AAAMQfAAADEDwAQAwAMEHAMAABB8XnHXr1mns2LHq2rWrmjZtqosvvlhDhw5VUVFRtX0HDhwol8sll8ulBg0aKD4+Xp07d9bw4cP11ltv6eTJk2Gvf/vtt8vlcmnixIl2HE5ULVq0KPTn4XK51KhRI7Vv31733nuvvvzyy9B+GzZskMvl0oYNG8JeY8uWLZo5c6a++eYb+wYHUGsEHxecnJwc/fOf/9TkyZO1evVqvfjiiyorK1O/fv20bt26avtfcskl2rp1q7Zs2aIVK1Zo6tSpOnbsmIYPH66BAwfK7/ef99plZWV67733JEmvv/66jh8/bttxRdPChQu1detW5efn65e//KWWLl2q/v37q6KiotbPvWXLFs2aNYvgA3VMI6cHAMI1d+5ctWnTpsp9N910kzp37qynnnpK119/fZWvNW7cWP369aty37hx47Rw4UKNHTtW999/v/Ly8s5r7cWLF+u7777T4MGD9f777+udd97RyJEjf/Rxx44dU1xcnFwuV7Wvffvtt2rSpMl5rW+Xnj17KiUlRZJ03XXXqbKyUk888YRWrFihUaNGRXUWANHBGT4uOKfHXpKaNWum7t27q7S09Lyf595779XNN9+sN998U1988cV5Pebll19WQkKCXnnlFTVu3Fgvv/xytX1OvWz+wQcfaOzYsWrdurWaNGmiYDCogQMHqmfPntq0aZPS0tLUpEkTjR07VpKUl5en9PR0tWvXTo0bN1a3bt00derUKmfdr776qlwul7Zu3Vpt3ccff1wxMTE6cODAef8ZnHLqH0Q/9uewatUqpaamqkmTJoqPj9eNN95YZZaZM2fqd7/7nSQpKSkp9NZBTd4aAGAvgo96we/3a/v27erRo0dYj7v11ltlWZY2b978o/tu2bJFu3fv1j333KOWLVtq2LBhWrdunfbv33/G/ceOHauYmBi9+uqreuuttxQTEyNJOnjwoO6++26NHDlSq1ev1oQJEyRJe/bs0c0336wFCxZo7dq1mjJlit544w0NGTIk9JwjRoxQ27ZtNXfu3Cprff/995o3b55+/vOfKzExMaw/A0nau3evJKl169Zn3WfJkiUaOnSoPB6Pli5dqgULFujrr7/WwIED9dFHH0n6zysnkyZNkiS988472rp1q7Zu3aorrrgi7JmAaDl+/LgCgYAtW51+m88C6oFRo0ZZjRo1srZt21bl/gEDBlg9evQ46+PWrFljSbKeeeaZH11j7NixliRr9+7dlmVZ1vr16y1J1qOPPlplv4ULF1qSrHvuuafacwwYMMCSZH344YfnXOvkyZPWd999Z23cuNGSZH366aehr82YMcOKjY21vvrqq9B9eXl5liRr48aN53zeU7MVFBRY3333nVVeXm699957VuvWra34+Hjr0KFDVY5t/fr1lmVZVmVlpZWYmGj16tXLqqysDD1feXm51aZNGystLS1037PPPmtJsvbv33/OWYC64NixY1ZbyZJNm8fjsbp06WJ169bNmjNnjtOHVwVn+LjgPfroo3r99df1hz/8QcnJyWE91rKs89rv6NGjeuONN5SWlqauXbtKkgYMGKBOnTpp0aJFZ7zaf9iwYWd8rubNm1e7zkCS9u3bp5EjR6pt27Zq2LChYmJiNGDAAEnS7t27Q/s98MADkqT58+eH7pszZ4569eqla6+99ryOp1+/foqJiVF8fLxuueUWtW3bVmvWrFFCQsIZ9//888914MABjR49Wg0a/O/bRrNmzTRs2DAVFBTo22+/Pa+1gbrkxIkTOiSpVJK/lluppEAgoI8//li7du1SZmZmlI/m3LhoDxe0WbNmafbs2XryySdr9DG5U+9Z/9jL4Hl5eTp69KjuvPPOKlef33nnncrOzlZ+fr5+9rOfVXlMu3btzvhcZ7r/6NGj6t+/v+Li4jR79mxdeumlatKkiUpLS3X77bfr2LFjoX0TEhI0YsQIzZs3T1OnTtXOnTu1efNmzZs373wPW4sXL1a3bt3UqFEjJSQknHXWU44cOXLW2RMTE3Xy5El9/fXXUb/4ELCL579bfUbwccGaNWuWZs6cqZkzZ2r69Ok1eo5Vq1bJ5XL96JnxggULJElTpkzRlClTzvj104N/pivyz3b/unXrdODAAW3YsCF0Vi/prB9tmzx5sl599VWtXLlSa9eu1UUXXRTW1fXdunULXaV/Plq2bCnpP9cfnO7AgQNq0KCBmjdvft7PByD6CD4uSE888YRmzpyp//u//9OMGTNq9BwLFy7UmjVrNHLkSHXo0OGs++3evVtbt27VsGHDzvgqwuzZs7Vy5UodOXIkFMZwnfpHgNvtrnL/2c7ak5OTlZaWpmeeeUZ///vfdf/996tp06Y1Wvt8dOnSRRdffLGWLFmiBx98MDRvRUWF3n777dCV+z88hh++KgHAeQQfF5znnntOjz32mG666SYNHjxYBQUFVb5++mfujx07Ftrn2LFj2rdvn1asWKH33ntPAwYM0B//+Mdzrnfq7P6hhx7SlVdeWe3r5eXl+vDDD/Xaa69p8uTJNTqmtLQ0NW/eXOPHj9eMGTMUExOj119/XZ9++ulZHzN58mSNGDFCLpcrdKV/pDRo0EC///3vNWrUKN1yyy361a9+pWAwqGeffVbffPONnn766dC+vXr1kiS9+OKLGjNmjGJiYtSlSxfFx8dHdEYAP8LpqwaBcJ260v1s27n2bdq0qXXJJZdYd9xxh/Xmm29WueL8TE6cOGG1adPGuuyyy866z/fff2+1b9/e6tWrl2VZ/7sSvrCw8Iyzn+1TA1u2bLFSU1OtJk2aWK1bt7bGjRtnbd++3ZJkLVy4sNr+wWDQcrvd1k033XTOY/ihc832Q6dfpX/KihUrrKuuusqKi4uzmjZtag0aNMj661//Wu3x06ZNsxITE60GDRqc8XmAusLv91uSLL9kWbXc/P/9PuP3+50+rDNyWdZ5XqYMoE559913deutt+r999/XzTff7PQ4wAUpEAjI6/XKr9pftBeQ5NV/fi6Ix1P3LgHkJX3gArNr1y598cUX+u1vf6vLLrtMGRkZTo8E4ALA5/CBC8yECRN06623qnnz5lq6dOlZPw0AAD/EGT5wgeHn0gOoCc7wAQAwAMEHAMAABB8AAANE/T38kydP6sCBA4qPj+diIwDAWVmWpfLyciUmJlb5pU2omagH/8CBA/L5fNFeFgBwgSotLVX79u2dHuOCF/Xgn/rxmqWlpXXyBxPgPHm9Tk8AQJL8fqcniJhAICCfz8ePZbZJ1IN/6mV8j8dD8AGgtgz4Psrbv/bgTREAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxQo+C/9NJLSkpKUlxcnJKTk7V582a75wIAADYKO/h5eXmaMmWKHnnkEX3yySfq37+/MjIyVFJSEon5AACADcIO/vPPP6/77rtP48aNU7du3fTCCy/I5/MpJycnEvMBAAAbhBX8EydOqKioSOnp6VXuT09P15YtW2wdDAAA2KdRODsfPnxYlZWVSkhIqHJ/QkKCDh06dMbHBINBBYPB0O1AIFCDMQEAQG3U6KI9l8tV5bZlWdXuOyU7O1terze0+Xy+miwJAABqIazgt2rVSg0bNqx2Nl9WVlbtrP+UadOmye/3h7bS0tKaTwsAAGokrODHxsYqOTlZ+fn5Ve7Pz89XWlraGR/jdrvl8XiqbAAAILrCeg9fkrKysjR69GilpKQoNTVVubm5Kikp0fjx4yMxHwAAsEHYwR8xYoSOHDmixx9/XAcPHlTPnj21evVqdezYMRLzAQAAG7gsy7KiuWAgEJDX65Xf7+fl/QvZWS7SBBBl0f0WHlXR6EVoDUm1XSEgySvV2b7xs/QBADAAwQcAwAAEHwAAAxB8AAAMQPABADAAwQcAwAAEHwAAAxB8AAAMQPABAHDApk2bNGTIECUmJsrlcmnFihURXY/gAwDggIqKCvXp00dz5syJynph/yx9AABQexkZGcrIyIjaegQfAAAbBQKBKrfdbrfcbrdD0/wPL+kDAGAjn88nr9cb2rKzs50eSRJn+AAA2Kq0tLTKb8urC2f3EsEHAMBWHo+HX48LAACcwRk+AAAOOHr0qPbu3Ru6vX//fhUXF6tFixbq0KGD7esRfAAAHLBt2zZdd911odtZWVmSpDFjxmjRokW2r0fwAQBwwMCBA2VZVtTW4z18AAAMQPABADAAL+kDZxO9V9oAIOI4wwcAwAAEHwAAAxB8AAAMQPABADAAwQcAwAAEHwAAAxB8AAAMQPABADAAwQcAwAAEHwAAAxB8AAAMQPABADAAwQcAwAAEHwAAAxB8AAAMQPABADAAwQcAwAAEHwAAAxB8AAAMQPABADAAwQcAwAAEHwAAAxB8AAAMQPABADBA2MHftGmThgwZosTERLlcLq1YsSICYwEAADuFHfyKigr16dNHc+bMicQ8AAAgAhqF+4CMjAxlZGREYhYAABAhYQc/XMFgUMFgMHQ7EAhEekkAAHCaiF+0l52dLa/XG9p8Pl+klwQAAKeJePCnTZsmv98f2kpLSyO9JAAAOE3EX9J3u91yu92RXgYAAJwDn8MHAMAAYZ/hHz16VHv37g3d3r9/v4qLi9WiRQt16NDB1uEAAIA9wg7+tm3bdN1114VuZ2VlSZLGjBmjRYsW2TYYAACwT9jBHzhwoCzLisQsAAAgQngPHwAAAxB8AAAMQPABADAAwQcAwAAEHwAAAxB8AAAMQPABADAAwQcAwAAEHwAAAxB8AAAMQPABADAAwQcAwAAEHwAAAxB8AAAMQPABADAAwQcAwAAEHwAAAxB8AAD8fsmyarf5/ZKkvn37qnv37po7d67DB1VVI6cHAACgPiksLJTH43F6jGo4wwcAwAAEHwAAA/CSPnA2LqcHgC0spwcA6gbO8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAwQVvCzs7PVt29fxcfHq02bNrrtttv0+eefR2o2AABgk7CCv3HjRmVmZqqgoED5+fn6/vvvlZ6eroqKikjNBwAAbNAonJ3Xrl1b5fbChQvVpk0bFRUV6dprr7V1MAAAYJ+wgn86v98vSWrRosVZ9wkGgwoGg6HbgUCgNksCAIAaqPFFe5ZlKSsrS9dcc4169ux51v2ys7Pl9XpDm8/nq+mSAACghmoc/IkTJ+qzzz7T0qVLz7nftGnT5Pf7Q1tpaWlNlwQAADVUo5f0J02apFWrVmnTpk1q3779Ofd1u91yu901Gg4AANgjrOBblqVJkyZp+fLl2rBhg5KSkiI1FwAAsFFYwc/MzNSSJUu0cuVKxcfH69ChQ5Ikr9erxo0bR2RAAABQe2G9h5+TkyO/36+BAweqXbt2oS0vLy9S8wEAABuE/ZI+AAC48PCz9AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAIS+99JKSkpIUFxen5ORkbd68OWJrEXwAAByQl5enKVOm6JFHHtEnn3yi/v37KyMjQyUlJRFZj+ADAOCA559/Xvfdd5/GjRunbt266YUXXpDP51NOTk5E1msUkWdF/Wc5PQBs4XJ6gCio78do1fcDvPAEAoEqt91ut9xud5X7Tpw4oaKiIk2dOrXK/enp6dqyZUtE5uIMHwAAG/l8Pnm93tCWnZ1dbZ/Dhw+rsrJSCQkJVe5PSEjQoUOHIjIXZ/gAANiotLRUHo8ndPv0s/sfcrmqvkJjWVa1++xC8AEAsJHH46kS/DNp1aqVGjZsWO1svqysrNpZv114SR8AgCiLjY1VcnKy8vPzq9yfn5+vtLS0iKzJGT4AAA7IysrS6NGjlZKSotTUVOXm5qqkpETjx4+PyHoEHwAAB4wYMUJHjhzR448/roMHD6pnz55avXq1OnbsGJH1CD4AAA6ZMGGCJkyYEJW1eA8fAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADEHwAAAxA8AEAMADBBwDAAAQfAAADhBX8nJwc9e7dWx6PRx6PR6mpqVqzZk2kZgMAADYJK/jt27fX008/rW3btmnbtm26/vrrNXToUO3cuTNS8wEAABs0CmfnIUOGVLn95JNPKicnRwUFBerRo4etgwEAAPuEFfwfqqys1JtvvqmKigqlpqbaORMAALBZ2MHfsWOHUlNTdfz4cTVr1kzLly9X9+7dz7p/MBhUMBgM3Q4EAjWbFAAA1FjYV+l36dJFxcXFKigo0AMPPKAxY8Zo165dZ90/OztbXq83tPl8vloNDAAAwueyLMuqzRPccMMN6tSpk+bNm3fGr5/pDN/n88nv98vj8dRmaTjK5fQAsAP/N174avUdvG4LBCSvVxHtRSAQkNfrtWUNO58rEmr8Hv4plmVVCfrp3G633G53bZcBAAC1EFbwp0+froyMDPl8PpWXl2vZsmXasGGD1q5dG6n5AACADcIK/ldffaXRo0fr4MGD8nq96t27t9auXasbb7wxUvMBAAAbhBX8BQsWRGoOAAAQQfwsfQAADEDwAQAwAMEHAMAABB8AAAMQfAAADEDwAQAwAMEHAMAABB8AAAMQfAAADEDwAQAwAMEHAMAABB8AAAMQfAAADEDwAQAwAMEHAMAABB8AAAMQfAAADEDwAQAwAMEHAMAABB8AAAMQfAAADNDIsZW9XseWjgrL6QFQay6nB4gC/p5e+Ez4ewpbcIYPAIABCD4AAAYg+AAAGIDgAwBgAIIPAIABCD4AAPLqPx95qM32n0+f9e3bV927d9fcuXOjewg/wrmP5QEAUA8VFhbK4/E4PUY1nOEDAGAAgg8AgAEIPgAABiD4AAAYgOADAGAAgg8AgAEIPgAABiD4AAAYgOADAGAAgg8AgAEIPgAABiD4AAAYgOADAGAAgg8AgAEIPgAABiD4AAAYgOADAGCAWgU/OztbLpdLU6ZMsWkcAAAQCTUOfmFhoXJzc9W7d2875wEAABFQo+AfPXpUo0aN0vz589W8eXO7ZwIAADarUfAzMzM1ePBg3XDDDT+6bzAYVCAQqLIBAIDoahTuA5YtW6bt27ersLDwvPbPzs7WrFmzwh4MAADYJ6wz/NLSUk2ePFmvvfaa4uLizusx06ZNk9/vD22lpaU1GhQAANRcWGf4RUVFKisrU3Jycui+yspKbdq0SXPmzFEwGFTDhg2rPMbtdsvtdtszLQAAqJGwgj9o0CDt2LGjyn333nuvunbtqocffrha7AEAQN0QVvDj4+PVs2fPKvc1bdpULVu2rHY/AACoO/hJewAAGCDsq/RPt2HDBhvGAAAAkcQZPgAABiD4AAAYgOADAGAAgg8AgAEIPgAABiD4AAAYgOADAGAAgg8AgAEIPgAABiD4AAAYgOADAGAAgg8AgAEIPgAABiD4AAAYgOADAGAAgg8AgAEIPgAABiD4AAAYgOADAGAAgg8AgAEIPgAABmjk9ABAnWU5PUAUuJweALVWn/+eBiR5nR6i/uAMHwAAAxB8AAAMQPABADAAwQcAwAAEHwAAAxB8AADquCeffFJpaWlq0qSJLrrooho9B8EHAKCOO3HihIYPH64HHnigxs/B5/ABAKjjZs2aJUlatGhRjZ+D4AMAYKNAIFDlttvtltvtdmia/+ElfQAAbOTz+eT1ekNbdna20yNJIvgAANiqtLRUfr8/tE2bNu2M+82cOVMul+uc27Zt22ybi5f0AQCwkcfjkcfj+dH9Jk6cqLvuuuuc+/zkJz+xaSqCDwCAI1q1aqVWrVpFbT2CDwBAHVdSUqJ///vfKikpUWVlpYqLiyVJnTt3VrNmzc7rOQg+AAB13GOPPaZXXnkldPvyyy+XJK1fv14DBw48r+fgoj0AAOq4RYsWybKsatv5xl4i+AAAGIHgAwBgAIIPAIABCD4AAAYg+AAAGIDgAwBgAIIPAIABCD4AAAYIK/hn+s0+bdu2jdRsAADAJmH/aN0ePXroL3/5S+h2w4YNbR0IAADYL+zgN2rUiLN6AAAuMGG/h79nzx4lJiYqKSlJd911l/bt23fO/YPBoAKBQJUNAABEV1jBv+qqq7R48WL9+c9/1vz583Xo0CGlpaXpyJEjZ31Mdna2vF5vaPP5fLUeGgAAhMdlWZZV0wdXVFSoU6dOeuihh5SVlXXGfYLBoILBYOh2IBCQz+eTX5KnpgtfCGr8pwpEkcvpAVBr9fh7TSAgeb2S3++XxxOZYgQCAXm9Xvn9Um2XiMa8tRH2e/g/1LRpU/Xq1Ut79uw56z5ut1tut7s2ywAAgFqq1efwg8Ggdu/erXbt2tk1DwAAiICwgv/ggw9q48aN2r9/v/72t7/pjjvuUCAQ0JgxYyI1HwAAsEFYL+n/61//0i9+8QsdPnxYrVu3Vr9+/VRQUKCOHTtGaj4AAGCDsIK/bNmySM0BAAAiiJ+lDwCAAQg+AAAGIPgAABiA4AMAYACCDwCAAQg+AAAGIPgAABiA4AMAYACCDwCAAQg+AAAGIPgAABiA4AMAYACCDwCAAQg+AAAGIPgAABiA4AMAYACCDwCAAQg+AAAGIPgAABiA4AMAYIBG0V7QsixJUiDaC0dbvT9AAHVCPf5eE/jvsZ3qBmon6sEvLy+XJPmivXC0eZ0eAIARDPheU15eLq/XgAONsKgHPzExUaWlpYqPj5fL5Yr4eoFAQD6fT6WlpfJ4PBFfzwn1/Rjr+/FJHGN9UN+PT4r+MVqWpfLyciUmJkZ8LRNEPfgNGjRQ+/bto72sPB5Pvf2P8JT6foz1/fgkjrE+qO/HJ0X3GDmztw8X7QEAYACCDwCAAep98N1ut2bMmCG32+30KBFT34+xvh+fxDHWB/X9+CQzjrE+c1l83gEAYKhAICCv1yu/X6rtZQmBgOT1Sn6/v05ex1Hvz/ABAADBBwDACAQfAAADEHwAAAxQr4P/0ksvKSkpSXFxcUpOTtbmzZudHslWmzZt0pAhQ5SYmCiXy6UVK1Y4PZKtsrOz1bdvX8XHx6tNmza67bbb9Pnnnzs9lq1ycnLUu3fv0A8ySU1N1Zo1a5weK2Kys7Plcrk0ZcoUp0exzcyZM+Vyuapsbdu2dXos23355Ze6++671bJlSzVp0kSXXXaZioqKnB4LYai3wc/Ly9OUKVP0yCOP6JNPPlH//v2VkZGhkpISp0ezTUVFhfr06aM5c+Y4PUpEbNy4UZmZmSooKFB+fr6+//57paenq6KiwunRbNO+fXs9/fTT2rZtm7Zt26brr79eQ4cO1c6dO50ezXaFhYXKzc1V7969nR7Fdj169NDBgwdD244dO5weyVZff/21rr76asXExGjNmjXatWuXnnvuOV100UVOj4ZwWPXUlVdeaY0fP77KfV27drWmTp3q0ESRJclavny502NEVFlZmSXJ2rhxo9OjRFTz5s2tP/3pT06PYavy8nLrpz/9qZWfn28NGDDAmjx5stMj2WbGjBlWnz59nB4joh5++GHrmmuucXqMiPD7/ZYky++XZVm12/x+/fe5/NE/kPNQL8/wT5w4oaKiIqWnp1e5Pz09XVu2bHFoKtSW3++XJLVo0cLhSSKjsrJSy5YtU0VFhVJTU50ex1aZmZkaPHiwbrjhBqdHiYg9e/YoMTFRSUlJuuuuu7Rv3z6nR7LVqlWrlJKSouHDh6tNmza6/PLLNX/+fKfHslUgYM9Wl0X9l+dEw+HDh1VZWamEhIQq9yckJOjQoUMOTYXasCxLWVlZuuaaa9SzZ0+nx7HVjh07lJqaquPHj6tZs2Zavny5unfv7vRYtlm2bJm2b9+uwsJCp0eJiKuuukqLFy/WpZdeqq+++kqzZ89WWlqadu7cqZYtWzo9ni327dunnJwcZWVlafr06fr444/161//Wm63W/fcc4/T49VKbGys2rZtK5/PnjZ4PB5deeWVatCggTIzM5WZmWnL89qhXgb/lNN//a5lWVH5lbyw38SJE/XZZ5/po48+cnoU23Xp0kXFxcX65ptv9Pbbb2vMmDHauHFjvYh+aWmpJk+erA8++EBxcXFOjxMRGRkZof/dq1cvpaamqlOnTnrllVeUlZXl4GT2OXnypFJSUvTUU09Jki6//HLt3LlTOTk5F3zw4+LitH//fp04ccKW54uNja2zf9frZfBbtWqlhg0bVjubLysrq3bWj7pv0qRJWrVqlTZt2uTIr1aOtNjYWHXu3FmSlJKSosLCQr344ouaN2+ew5PVXlFRkcrKypScnBy6r7KyUps2bdKcOXMUDAbVsGFDBye0X9OmTdWrVy/t2bPH6VFs065du2r/AO3WrZvefvtthyayV1xcXJ2NtJ3q5Xv4sbGxSk5OVn5+fpX78/PzlZaW5tBUCJdlWZo4caLeeecdrVu3TklJSU6PFBWWZSkYDDo9hi0GDRqkHTt2qLi4OLSlpKRo1KhRKi4urnexl6RgMKjdu3erXbt2To9im6uvvrraR2L/8Y9/qGPHjg5NhJqol2f4kpSVlaXRo0crJSVFqampys3NVUlJicaPH+/0aLY5evSo9u7dG7q9f/9+FRcXq0WLFurQoYODk9kjMzNTS5Ys0cqVKxUfHx96xcbr9apx48YOT2eP6dOnKyMjQz6fT+Xl5Vq2bJk2bNigtWvXOj2aLeLj46tdc9G0aVO1bNmy3lyL8eCDD2rIkCHq0KGDysrKNHv2bAUCAY0ZM8bp0Wzzm9/8RmlpaXrqqad055136uOPP1Zubq5yc3OdHg3hcPZDApE1d+5cq2PHjlZsbKx1xRVX1LuPc61fv96SVG0bM2aM06PZ4kzHJslauHCh06PZZuzYsaG/o61bt7YGDRpkffDBB06PFVH17WN5I0aMsNq1a2fFxMRYiYmJ1u23327t3LnT6bFs9+6771o9e/a03G631bVrVys3N9fpkRAmfj0uAAAGqJfv4QMAgKoIPgAABiD4AAAYgOADAGAAgg8AgAEIPgAABiD4AAAYgOADAGAAgg8AgAEIPgAABiD4AAAYgOADAGCA/weL9B8Zxo15KQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "game_num = 1\n",
    "\n",
    "# Assuming data_2d_arrays is already defined and contains the 2D arrays\n",
    "# Display the 2D array for the a row\n",
    "print('Table:\\n', X[game_num])\n",
    "print('Winner:', y[game_num])\n",
    "\n",
    "array_to_plot = X.iloc[game_num]\n",
    "\n",
    "# Define a custom colormap\n",
    "cmap = mcolors.ListedColormap(['yellow', 'white', 'red'])\n",
    "bounds = [-1.5, -0.5, 0.5, 1.5]\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "# Plot the 2D array\n",
    "plt.imshow(array_to_plot, cmap=cmap, norm=norm)\n",
    "plt.colorbar(ticks=[-1, 0, 1])\n",
    "plt.title('2D Array Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Very naive model that only actually learns if a board is won or not and by who."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8513222877170623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Flatten the 6x7 2D arrays back to 1D arrays for logistic regression\n",
    "X_flat = X.apply(lambda x: x.flatten())\n",
    "X_flat = np.stack(X_flat.values)\n",
    "\n",
    "# Drop rows with NaN values in y\n",
    "non_nan_indices = ~np.isnan(y)\n",
    "X_flat = X_flat[non_nan_indices]\n",
    "y = y[non_nan_indices]\n",
    "\n",
    "# Split the data into training and testing sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (MLP) Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty naive approach, but it should still work in theory. Other models like Random Forest, SVM, etc, should be tried to see if they perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset (assuming it's a CSV file)\n",
    "data = pd.read_csv('c4_game_database.csv')\n",
    "\n",
    "# Sample dataset structure\n",
    "# For demonstration, letâ€™s create a sample DataFrame based on your column names\n",
    "columns = [f'pos_{i:02}' for i in range(1, 43)] + ['winner']\n",
    "# Assume df is your DataFrame with 42 positions and a winner column\n",
    "\n",
    "# Separate the board positions and the winner column\n",
    "X = data[columns[:-1]].values  # The 42 board positions\n",
    "y_winner = data['winner'].values  # The winner outcome\n",
    "\n",
    "# Convert `winner` to a 7-element probability vector\n",
    "y = np.zeros((len(y_winner), 7))\n",
    "y[y_winner == 1] = 1    # If Player 1 won, set all columns to 1\n",
    "y[y_winner == -1] = 0   # If Player 2 won, set all columns to 0\n",
    "y[y_winner == 0] = 0.5  # If tie, set all columns to 0.5\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.2397\n",
      "Epoch [20/50], Loss: 0.2202\n",
      "Epoch [30/50], Loss: 0.1959\n",
      "Epoch [40/50], Loss: 0.1800\n",
      "Epoch [50/50], Loss: 0.1575\n",
      "Loss on test set: 0.1552\n"
     ]
    }
   ],
   "source": [
    "# Define the MLP model\n",
    "class Connect4MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Connect4MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 64)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(64, 128)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(128, 256)  # Third hidden layer\n",
    "        self.fc4 = nn.Linear(256, 512)  # Fourth hidden layer\n",
    "        self.fc5 = nn.Linear(512, 256)  # Fifth hidden layer\n",
    "        self.fc6 = nn.Linear(256, 128)  # Sixth hidden layer\n",
    "        self.fc7 = nn.Linear(128, 64)  # Seventh hidden layer\n",
    "        self.fc8 = nn.Linear(64, 32)  # Eighth hidden layer\n",
    "        self.fc9 = nn.Linear(32, 7)   # Output layer (7 probabilities for each column)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = torch.relu(self.fc7(x))\n",
    "        x = torch.relu(self.fc8(x))\n",
    "        x = torch.sigmoid(self.fc9(x))  # Sigmoid to output probabilities\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Connect4MLP()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression on probabilities\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    test_loss = criterion(test_outputs, y_test).item()\n",
    "    print(f'Loss on test set: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (376640, 42)\n",
      "y shape: (376640, 7)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('c4_game_database.csv', on_bad_lines='skip')\n",
    "\n",
    "# Prepare the features (X) and the target labels (y)\n",
    "X = data.drop(columns=['winner']).values  # 42 positions\n",
    "y_winner = data['winner'].values  # Winner outcome\n",
    "\n",
    "# Convert the 'winner' column into a 7-element probability vector\n",
    "y = np.zeros((len(y_winner), 7))\n",
    "\n",
    "y[y_winner == 1] = 1    # If Player 1 won, set all columns to 1\n",
    "y[y_winner == -1] = 0   # If Player 2 won, set all columns to 0\n",
    "y[y_winner == 0] = 0.5  # If tie, set all columns to 0.5\n",
    "\n",
    "# Check the shapes of X and y\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.2392\n",
      "Epoch [20/50], Loss: 0.2359\n",
      "Epoch [30/50], Loss: 0.2291\n",
      "Epoch [40/50], Loss: 0.2181\n",
      "Epoch [50/50], Loss: 0.2058\n",
      "Loss on test set: 0.2051\n"
     ]
    }
   ],
   "source": [
    "# Assuming `X` contains the 42 board positions and `y` contains the 7 probability targets for each move\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to torch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)  # Float for probability output\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the MLP model\n",
    "class Connect4MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Connect4MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(42, 64)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(64, 32)  # Second hidden layer\n",
    "        self.fc3 = nn.Linear(32, 7)   # Output layer (7 probabilities for each column)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Sigmoid to output probabilities\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Connect4MLP()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression on probabilities\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    test_loss = criterion(test_outputs, y_test).item()\n",
    "    print(f'Loss on test set: {test_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 0.2371\n",
      "Epoch [20/50], Loss: 0.2162\n",
      "Epoch [30/50], Loss: 0.1746\n",
      "Epoch [40/50], Loss: 0.1564\n",
      "Epoch [50/50], Loss: 0.1438\n",
      "Loss on test set: 0.1429\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming `X` contains the 42 board positions reshaped as (num_samples, 6, 7)\n",
    "# and `y` contains the 7 probability targets for each move\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to torch tensors, reshaping X for CNN input\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).reshape(-1, 1, 6, 7)  # Add channel dimension\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).reshape(-1, 1, 6, 7)    # Add channel dimension\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the CNN model\n",
    "class Connect4CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Connect4CNN, self).__init__()\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # Output size: 16x6x7\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) # Output size: 32x6x7\n",
    "        self.fc1 = nn.Linear(32 * 6 * 7, 64)   # Flatten and dense layer\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 7)  # Output layer (7 probabilities for each column)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Sigmoid to output probabilities\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Connect4CNN()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for regression on probabilities\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation on test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    test_loss = criterion(test_outputs, y_test).item()\n",
    "    print(f'Loss on test set: {test_loss:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
